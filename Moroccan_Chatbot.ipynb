{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moroccan-Chatbot",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/BEKRINEY/Moroccan-Chatbot/blob/master/Moroccan_Chatbot.ipynb",
      "authorship_tag": "ABX9TyMDU12GvzdlQ+UcDXTSIxNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BEKRINEY/Moroccan-Chatbot/blob/master/Moroccan_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VtZqyk8gLZz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Import necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsZYIz4DB73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import random\n",
        "import string # to process standard python strings\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65notkFPDZiY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuixpA9-o6Yu",
        "colab_type": "text"
      },
      "source": [
        "#Downloading and installing NLTK "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO66eheygiKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e1ad5cd2-ec19-4527-a530-512e3f1f5ef7"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQt4DhagPwJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGwNrxqypIcm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Installing NLTK PackagesÂ¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUo231FgDZ52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "71a589cf-5fde-4e47-a32a-090e798aeb47"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True) # for downloading packages\n",
        "#nltk.download('punkt') # first-time use only\n",
        "#nltk.download('wordnet') # first-time use only"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwtYPtGmpRdj",
        "colab_type": "text"
      },
      "source": [
        "#Reading in the corpus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqNowDDcx1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open('/content/drive/My Drive/Colab Notebooks/chatbot.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw = raw.lower()# converts to lowercase"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAr9pXnqppQ7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Tokenisation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQOY_lGc5wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrnUN3_epyDL",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XorHKbwc6w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK5-RAYXp7sY",
        "colab_type": "text"
      },
      "source": [
        "#Keyword matching "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kiJZL3_c88_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GREETING_INPUTS = (\"salam\", \"ahlan\", \"sbah lkhir\", \"mssa nour\", \"salam alaykom\",\"afin\",)\n",
        "GREETING_RESPONSES = [\"walaykom w salam\", \"ahlan\", \"*nods*\", \"sbah nour\", \"ahlan\", \"kay charafna dwi m3ana asidi!\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZQycBr7qAw5",
        "colab_type": "text"
      },
      "source": [
        "#Generating Response "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMWNqN3odBdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"Sma7 liya! ma fhamtekch\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z0nRBwoxgIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "2d64d095-159d-40ad-bcb0-79715c22d68a"
      },
      "source": [
        "flag=True\n",
        "print(\"MOROBOT: Smiti MOROBOT. ghadi njawbk 3la 2as2ila dyalek 3la Chatbots. ila bghiti tkhroj, ktab bslama!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bslama'):\n",
        "        if(user_response=='chkoran' or user_response=='chokran jzilan' ):\n",
        "            flag=False\n",
        "            print(\"MOROBOT: Marhba sidi..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"MOROBOT: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"MOROBOT: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"MOROBOT: Bsalam! thala f rasek..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MOROBOT: Smiti MOROBOT. ghadi njawbk 3la 2as2ila dyalek 3la Chatbots. ila bghiti tkhroj, ktab bslama!\n",
            "bghit n3raf chno howa chatbot ?\n",
            "MOROBOT: design\n",
            "the chatbot design is the process that defines the interaction between the user and the chatbot.the chatbot designer will define the chatbot personality, the questions that will be asked to the users, and the overall interaction.it can be viewed as a subset of the conversational design.\n",
            "wakha\n",
            "MOROBOT: Sma7 liya! ma fhamtekch\n",
            "ahlan\n",
            "MOROBOT: walaykom w salam\n",
            "salam\n",
            "MOROBOT: walaykom w salam\n",
            "sbah nour\n",
            "MOROBOT: Sma7 liya! ma fhamtekch\n",
            "sbah lkhir\n",
            "MOROBOT: Sma7 liya! ma fhamtekch\n",
            "afin\n",
            "MOROBOT: walaykom w salam\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
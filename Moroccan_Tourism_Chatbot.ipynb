{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moroccan_Tourism_Chatbot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/BEKRINEY/Moroccan-Chatbot/blob/master/Moroccan_Tourism_Chatbot.ipynb",
      "authorship_tag": "ABX9TyNYnTUm0OUAS9oythvC55k2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BEKRINEY/Moroccan-Chatbot/blob/master/Moroccan_Tourism_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVc1RFzkjV3T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "#**Moroccan Tourisme Chatbot**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPTbLnqAjnAg",
        "colab_type": "text"
      },
      "source": [
        "Un chatbot est un logiciel alimenté par l'intelligence artificielle d'un appareil (Siri, Alexa, Google Assistant, etc.), d'une application, d'un site web ou d'autres réseaux qui tentent d'évaluer les besoins des consommateurs et les aident ensuite à effectuer une tâche particulière, comme une transaction commerciale, une réservation d'hôtel, la soumission d'un formulaire, etc. Aujourd'hui, presque toutes les entreprises ont mis en place un chatbot pour dialoguer avec les utilisateurs. Voici quelques-unes des manières dont les entreprises utilisent les chatbots :\n",
        "\n",
        "- Pour fournir des informations sur les vols\n",
        "- pour relier les clients et leurs finances\n",
        "- En tant qu'assistance à la clientèle\n",
        "\n",
        "Les possibilités sont (presque) illimitées.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCGkhOYkKCq",
        "colab_type": "text"
      },
      "source": [
        "**Morrocan Tourism Chatbot** est un chatbot qui permet d'aider les voyageurs qui vent visiter le maroc , alors il offre des informations sur la cuture , les places touristique , les repas de notre chére pays .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mISvYSX6xtN",
        "colab_type": "text"
      },
      "source": [
        "**Ce projet est venue dans le context de la pendémie COVID-19 qui a impacté le domaine touristique dans le monde entier et surtout que notre pays a connu une baisse de plus de 20% des recettes du tourisme.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99v78ZU8rZO",
        "colab_type": "text"
      },
      "source": [
        "#Comment les chatbots fonctionne ?\n",
        "\n",
        "Il existe en gros deux variantes de chatbots : Rule-Based et Self-learning..\n",
        "\n",
        "   1- Dans une approche **Rule-Based**, un bot répond à des questions basées sur certaines règles sur lesquelles il est formé. Les règles définies peuvent être très simples à très complexes. Les bots peuvent traiter des questions simples mais ne peuvent pas gérer des questions complexes.\n",
        "   2- Les bots **Self-learning** sont ceux qui utilisent certaines approches basées sur l'apprentissage automatique et sont définitivement plus efficaces que les bots basés sur des règles. Ces bots peuvent être de deux autres types : Retrieval Based ou bien Generative\n",
        "\n",
        "i) Dans les modèles **retrieval-based**, un chatbot utilise une certaine heuristique pour sélectionner une réponse à partir d'une bibliothèque de réponses prédéfinies. Le chatbot utilise le message et le contexte de la conversation pour sélectionner la meilleure réponse à partir d'une liste prédéfinie de messages de bot. Le contexte peut inclure une position actuelle dans l'arbre de dialogue, tous les messages précédents de la conversation, des variables préalablement enregistrées (par exemple, le nom d'utilisateur). Les heuristiques pour la sélection d'une réponse peuvent être conçues de différentes manières, de la logique conditionnelle \"if-else\" basée sur des règles aux classificateurs d'apprentissage machine.\n",
        "\n",
        "ii) Les bots générateurs (**Generative**) peuvent générer les réponses et pas toujours les réponses avec une des réponses d'un ensemble de réponses. Cela les rend plus intelligents car ils prennent mot à mot la requête et génèrent les réponses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai1KiAviGerU",
        "colab_type": "text"
      },
      "source": [
        "#Les technologies utlisées  :\n",
        "\n",
        "-Scikit library and NLTK. \n",
        "\n",
        "-NLP (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cn0O9dNHOaM",
        "colab_type": "text"
      },
      "source": [
        "**NLP (Natural Language Processing) :**\n",
        "\n",
        "Le domaine d'étude qui se concentre sur les interactions entre le langage humain et les ordinateurs est appelé traitement du langage naturel, ou PNL en abrégé. Il se situe à l'intersection de l'informatique, de l'intelligence artificielle et de la linguistique informatique [Wikipedia]. La PNL est un moyen pour les ordinateurs pour analyser, comprendre et déduire le sens du langage humain d'une manière intelligente et **utile**. En utilisant la PNL, les développeurs peuvent organiser et structurer les connaissances pour effectuer des tâches telles que le résumé automatique, la traduction, la reconnaissance d'entités nommées, l'extraction de relations, l'analyse des sentiments, la reconnaissance de la parole et la segmentation de sujets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GczFqLkD3br",
        "colab_type": "text"
      },
      "source": [
        "#Téléchargement et installation de NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1kWv6yTHlIf",
        "colab_type": "text"
      },
      "source": [
        "NLTK (Natural Language Toolkit) est une plateforme de référence pour la réalisation des programmes Python destinés à fonctionner avec des données en langage humain. Elle fournit des interfaces faciles à utiliser pour plus de 50 corpus et ressources lexicales telles que WordNet, ainsi qu'une suite de bibliothèques de traitement de texte pour la classification, la tokenisation, le balisage, l'analyse et le raisonnement sémantique, des enveloppes pour les bibliothèques de PNL de niveau industriel.\n",
        "\n",
        "La NLTK a été qualifiée de \"merveilleux outil pour l'enseignement et le travail en linguistique informatique utilisant Python\" et de \"bibliothèque étonnante pour jouer avec le langage naturel\".\n",
        "\n",
        "Le traitement du langage naturel avec Python fournit une introduction pratique à la programmation pour le traitement du langage. Je recommande vivement ce livre aux personnes qui débutent en PNL avec Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKIjpst2JJQh",
        "colab_type": "text"
      },
      "source": [
        "**Installer NLTK via la commande :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CjScDd5Dhaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRYLo76ILw3t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDzIdASuS7jx",
        "colab_type": "text"
      },
      "source": [
        "#l'importation des bibliothèques nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1clcNDPOlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string # to process standard python strings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjDnRhuYSr1i",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXJHrJfGTeAp",
        "colab_type": "text"
      },
      "source": [
        "#Corpus\n",
        "En commance par la lecture des données depuis notre corpus\n",
        "Morocco.txt qui contient plusieurs articles apropos du maroc , les villes , les repas marocaines .. récupérés depuis Wikipidia et les sites web de tourisme les plus connus via scraping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOAg0xT2TodI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open('/content/drive/My Drive/Colab Notebooks/Morocco.txt','r',errors = 'ignore')raw=f.read()raw=raw.lower()# converts to lowercasenltk.download('punkt') # first-time use only\n",
        "nltk.download('wordnet') # first-time use only\n",
        "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BboPI-U_Tuci",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#Text Pre- Processing with NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eHukMfX8iPT",
        "colab_type": "text"
      },
      "source": [
        "Le principal problème avec les données textuelles est qu'elles sont toutes au format texte (strings). Cependant, les algorithmes d'apprentissage automatique ont besoin d'une sorte de vecteur de caractéristiques numériques pour effectuer la tâche. Ainsi, avant de commencer un projet de PNL, nous devons le pré-traiter pour le rendre idéal pour le travail. Le pré-traitement d'un texte de base comprend :\n",
        "\n",
        "- La conversion de l'ensemble du texte **en majuscules ou en minuscules**, afin que l'algorithme ne traite pas les mêmes mots dans différents cas comme des mots différents\n",
        "- **La tokenisation :** La tokenisation est juste le terme utilisé pour décrire le processus de conversion des chaînes de texte normales en une liste de tokens, c'est-à-dire des mots que nous voulons vraiment. Le tokenizer de phrases peut être utilisé pour trouver la liste des phrases et le tokenizer de mots peut être utilisé pour trouver la liste des mots dans les chaînes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJv_CUSTTxKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgPT4PVYT0cH",
        "colab_type": "text"
      },
      "source": [
        "#Keyword matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSh1EuFsT3SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUWUxbssT8lX",
        "colab_type": "text"
      },
      "source": [
        "#Generating Response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cLFTP49UhKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Hnh3_YUm2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjjI-BlUvHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCORsg7hUx1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flag=True\n",
        "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO: Bye! take care..\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}